{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <p style=\"text-align: center;\"> <span style=\"color:yellowgreen\"> Exercise 6 - Coordinate Transformation </span></p>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In Ex 4 and Ex5, we focused on creating a package that extract information about the white lanes with respect to the camera position.  \n",
                "However, the problem is that this information is obtain with respect to where the camera is position as well as in pixel information.  \n",
                "We now focus on tools to transform this information into real world information.  \n",
                "In other words, we need to find the position of the robot in the lane, i.e., orientation and distance to center of the lane.\n",
                "\n",
                "\n",
                "In this exercise, we will learn about coordinate transformation as well as transforming pixel information to real world measures.\n",
                "The *goal* of this exercise is to:  \n",
                "1. Learn how to calculate coordinate transformations\n",
                "2. Learn about transforming image coordinates to robot coordinates\n",
                "3. Create a node that takes in duckietown_msgs/Vector2D message on a topic called /sensor_coord and"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <p style=\"text-align: center;\"> <span style=\"color:coral\"> Objectives </span></p>\n",
                "1. Calculate the position of four points by hand using coordinate transformations\n",
                "2. Create one ROS nodes that \n",
                "\t- Subscribes to topic `sensor_coord` that is duckietown_msgs/Vector2D message. That is the position of an object from obtained from the camera (sensor)\n",
                "\t- Calculate the point in robot-relative coordinates and publishes in a new topic called exactly `/robot_coord` as a Vector2D message.\n",
                "\t- Calculate the point in world coordinates and publishes in a new topic called exactly `/world_coord` as a Vector2D message.\n",
                "3. A launch file **(named ex6.launch)** to start all nodes to run the exercise.\n",
                "\t\n",
                "\n",
                "### Problem description \n",
                "\n",
                "Your robot is in position (5, 3) facing 45 degrees left of the y-axis (135 degrees relative to x-axis) in world coordinates.   \n",
                "It has a sensor pointed exactly behind the robot (180 degrees from forward/positive x-axis on the robot) and placed 1 m behind the center of the robot.\n",
                "\n",
                "- Robot position (5,3) facing 135 degrees in world coordinates\n",
                "- Sensor position (-1,0) facing 180 degrees in robot coordinates\n",
                "\n",
                "The sensor returns obstacles in the following locations (in the sensor coordinate frame):\n",
                "\n",
                "- (7,2)\n",
                "- (16,-1)\n",
                "- (-7,6)\n",
                "- (-8,-13)\n",
                "\n",
                "### ROS Package\n",
                "A package `coord_transf` has been created for you.    \n",
                "You need to add your node inside this package.    \n",
                "There is a node called `sensor.py` that publishes `Vector2D` messages to the `sensor_coord` topic.   \n",
                "`Vector2D` messages have variables `x` and `y` that will represent the `x` and `y` positions in a coordinate frame.   \n",
                "There is also a node called `coord_tranf_ex` that demonstrates some numpy operations such as vector creation and manipulation and matrix multiplication.  \n",
                "This node shows the transformation example in notebook 06c.   \n",
                "\n",
                "### ROS Nodes\n",
                "You will create one node.\n",
                "The node will: \n",
                "- Subscribes to topic `sensor_coord` that is duckietown_msgs/Vector2D message. That is the position of an object from obtained from the camera (sensor)\n",
                "- Calculate the point in robot-relative coordinates and publishes in a new topic called exactly `robot_coord` as a Vector2D message.\n",
                "- Calculate the point in world coordinates and publishes in a new topic called exactly `world_coord` as a Vector2D message.\n",
                "\n",
                "\n",
                "**Note:** ROS nodes will start at different times, so consider adding a slight delay before publishing commands.  \n",
                "Remember to make your node an executable: `chmod +x`\n",
                "\n",
                "\n",
                "### ROS Launch file\n",
                "Your launch file must start\n",
                "\n",
                "- The `sensor.py` node inside the package `coord_tranf` \n",
                "- The node you have created\n",
                "- Rostopic echo the `robot_coord` topic \n",
                "- Rostopic echo the `world_coord` topic\n",
                "\n",
                "\n",
                "\n",
                "## Notebooks information \n",
                "\n",
                "There are 4 notebooks covering\n",
                "- Frame representations: Explaining the use of coordinate frames (ex06a)\n",
                "- Frame Coordinate Transformation: Defining 2D and 3D rotation and translation operations, and special Euclidean Group with 2D and 3D matrix transforms (ex06b)\n",
                "- Transformation examples: Example of calculating robot global position after the robot moves and the global and robot coordinates of objects detected by a sensor in the robot (ex06c)\n",
                "- Camera to Coordinates: Describing the process of going from camera pixels to robot frame coordinates  (ex06d)\n",
                "\n",
                "\t\n",
                "\n",
                "## Reminders\n",
                "\n",
                "- `dts code editor --recipe ../ex6-recipe` opens the VS Code in the browser. You need to be inside the ex6 dir\n",
                "\n",
                "\t- Remember to build and source your package. You need to be in `ex_workspace` folder.\n",
                "\t- Remember to make your nodes executable. chmod +x command \n",
                "\t- You can test the logic of your code but you can't have the visuals. \n",
                "\n",
                "- `dts code workbench --recipe ../ex6-recipe` opens the VNC container in the browser. You need to be inside the ex6 dir\n",
                "\t- Remember to build and source your package. You need to be in `/code/catkin_ws` folder.\n",
                "\t- Use the roslaunch file to open all nodes\n",
                "\t- Use commands `rostopic list -v`, `rostopic echo topic_name`, and other ros debbuging tools to help debug errors. \n",
                "\n",
                "- `dts devel build` builds the Devel container. You need to be inside the `ex6-devel` dir\n",
                "\n",
                "- `dts devel run -X -M -f --cmd bash` runs the Devel container.  You need to be inside the `ex6-devel` dir.  This will transform your terminal into a container terminal with ROS and access to graphical interface.  \n",
                "\t- Remember to build and source your package. \n",
                "\t- Remember to make your nodes executable. chmod +x command \n",
                "\t- Use the roslaunch file to open all nodes\n",
                "\t- Use commands `rostopic list -v`, `rostopic echo topic_name`, and other ros debbuging tools to help debug errors. \n",
                "\n",
                "- `dts devel run attach` opens a new Devel container terminal.  You run this after running the container in a new VM terminal tab (not the terminal where you ran dts devel run -X -M -f --cmd bash).   \n",
                "You need to be inside the `ex6-devel` dir.   \n",
                "This will transform your terminal into a container terminal with ROS and access to graphical interface.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <p style=\"text-align: center;\"> <span style=\"color:coral;\">Submission </span></p>\n",
                "\n",
                "<a href=\"https://psu.instructure.com/courses/2335376/pages/github-submission-instructions\">Submission details instruction</a>\n",
                "\n",
                " 1. Check which files changed\n",
                "```bash\n",
                "git status\n",
                "```\n",
                "2. Add them to this staged commit\n",
                "```bash\n",
                "git add -A\n",
                "```\n",
                "3. Make the commit\n",
                "```bash\n",
                "git commit -m 'your message for the commit'\n",
                "```\n",
                "4. Push it to your repo on GitHub\n",
                "```bash\n",
                "git push\n",
                "```\n",
                "Up to this point, your git should be updated. The next commands are for the final exercise or lab submission\n",
                "\n",
                "5. Tag based on the exercise or lab.\n",
                "```bash\n",
                "git tag ex6\n",
                "```\n",
                "6. Push the tag to Github\n",
                "```bash\n",
                "git push origin ex6\n",
                "```\n",
                "7. Verify on Github.com that your submission is there, in the correct tag\n",
                "\n",
                "### <p style=\"text-align: center;\">Rubric</p>\n",
                "\n",
                "- ROS node to perform the transform for any Vector2D input 30%\n",
                "\t- Subscribes to correct topic *sensor_coord* \n",
                "\t- Transforms point in sensor-relative coordinates to robot-relative coordinates \n",
                "\t- Publishes the point in robot-relative coordinates to topic *robot_coord* as Vector2D message\n",
                "\t- Transforms point in sensor-relative coordinates to world-relative coordinates\n",
                "\t- Publishes the point in world-relative coordinates to topic *world_coord* as Vector2D message\n",
                "- Launch file with the correct name **ex6.launch** 10%\n",
                "- Written Answers 60%\n",
                "\t- Your name, repo URL, and the tag for this assignment\n",
                "\t- The name of the package and node you created\n",
                "\t- Calculating the coordinates by hand (10% for each answer below)\n",
                "\t\t- Draw the robot and sensor in the world coordinate frame (does not need to be to scale).\n",
                "\t\t- Find the transform from the sensor to the robot coordinate frame.\n",
                "\t\t- Find the transform from the robot to the world coordinate frame.\n",
                "\t\t- Find the transform from the sensor to the world coordinate frame.\n",
                "\t\t- Calculate the position of each of the four points above relative to the robot coordinate frame.\n",
                "\t\t- Calculate the position of each of the four points above relative to the world coordinate frame.\n",
                "\t- Any difficulties you had with this assignment\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.10 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "vscode": {
            "interpreter": {
                "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
